---
title: "Mini Data Analysis Milestone 2"
output: md_document
author: Jessica Sun
date: October 10, 2025
---

*To complete this milestone, you can edit [this `.rmd` file](https://github.com/UBC-STAT/STAT545.github.io/blob/main/content/mini-data-analysis/mini-project-2.Rmd) directly. Fill in the sections that are commented out with `<!--- start your work here--->`. When you are done, make sure to knit to an `.md` file by changing the output in the YAML header to `github_document`, before submitting a tagged release on canvas.*

# Welcome to the rest of your mini data analysis project!

In Milestone 1, you explored your data. and came up with research questions. This time, we will finish up our mini data analysis and obtain results for your data by:

-   Making summary tables and graphs
-   Manipulating special data types in R: factors and/or dates and times.
-   Fitting a model object to your data, and extract a result.
-   Reading and writing data as separate files.

We will also explore more in depth the concept of *tidy data.*

**NOTE**: The main purpose of the mini data analysis is to integrate what you learn in class in an analysis. Although each milestone provides a framework for you to conduct your analysis, it's possible that you might find the instructions too rigid for your data set. If this is the case, you may deviate from the instructions -- just make sure you're demonstrating a wide range of tools and techniques taught in this class, and indicate *why* you had to deviate. Feel free to contact the instructor in these cases.

# Instructions

**To complete this milestone**, edit [this very `.Rmd` file](https://github.com/UBC-STAT/STAT545.github.io/blob/main/content/mini-data-analysis/mini-project-2.Rmd) directly. Fill in the sections that are tagged with `<!--- start your work here--->`.

**To submit this milestone**, make sure to knit this `.Rmd` file to an `.md` file by changing the YAML output settings from `output: html_document` to `output: github_document`. Commit and push all of your work to your mini-analysis GitHub repository, and tag a release on GitHub. Then, submit a link to your tagged release on canvas.

**Points**: This milestone is worth 50 points: 45 for your analysis, and 5 for overall reproducibility, cleanliness, and coherence of the Github submission.

**Research Questions**: In Milestone 1, you chose four research questions to focus on. Wherever realistic, your work in this milestone should relate to these research questions whenever we ask for justification behind your work. In the case that some tasks in this milestone don't align well with one of your research questions, feel free to discuss your results in the context of a different research question.

# Learning Objectives

By the end of this milestone, you should:

-   Understand what *tidy* data is, and how to create it using `tidyr`.
-   Generate a reproducible and clear report using R Markdown.
-   Manipulating special data types in R: factors and/or dates and times.
-   Fitting a model object to your data, and extract a result.
-   Reading and writing data as separate files.

# Setup

Begin by loading your data and the tidyverse package below:

```{r, message = FALSE}
library(datateachr) # <- might contain the data you picked!
library(tidyverse)
library(stringr)
library(forcats)
library(broom)
library(here)
```

# Task 1: Process and summarize your data

From Milestone 1, you should have an idea of the basic structure of your dataset (e.g. number of rows and columns, class types, etc.). Here, we will start investigating your data more in-depth using various data manipulation functions.

### 1.1 (1 point)

First, write out the 4 research questions you defined in milestone 1 were. This will guide your work through milestone 2:

<!-------------------------- Start your work below ---------------------------->

1.  Why are so many of the discounted game prices higher than the non-discounted prices?

2.  How does the initial price of a game and its computer requirements affect its audience perception?

3.  Have discounts applied to games affected how they are reviewed recently compared to overall?

4.  What genre of games are the most popular to release and play over time?

    <!----------------------------------------------------------------------------->

Here, we will investigate your data using various data manipulation and graphing functions.

### 1.2 (8 points)

Now, for each of your four research questions, choose one task from options 1-4 (summarizing), and one other task from 4-8 (graphing). You should have 2 tasks done for each research question (8 total). Make sure it makes sense to do them! (e.g. don't use a numerical variables for a task that needs a categorical variable.). Comment on why each task helps (or doesn't!) answer the corresponding research question.

Ensure that the output of each operation is printed!

Also make sure that you're using dplyr and ggplot2 rather than base R. Outside of this project, you may find that you prefer using base R functions for certain tasks, and that's just fine! But part of this project is for you to practice the tools we learned in class, which is dplyr and ggplot2.

**Summarizing:**

1.  Compute the *range*, *mean*, and *two other summary statistics* of **one numerical variable** across the groups of **one categorical variable** from your data.
2.  Compute the number of observations for at least one of your categorical variables. Do not use the function `table()`!
3.  Create a categorical variable with 3 or more groups from an existing numerical variable. You can use this new variable in the other tasks! *An example: age in years into "child, teen, adult, senior".*
4.  Compute the proportion and counts in each category of one categorical variable across the groups of another categorical variable from your data. Do not use the function `table()`!

**Graphing:**

6.  Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.
7.  Make a graph where it makes sense to customize the alpha transparency.

Using variables and/or tables you made in one of the "Summarizing" tasks:

8.  Create a graph that has at least two geom layers.
9.  Create 3 histograms, with each histogram having different sized bins. Pick the "best" one and explain why it is the best.

Make sure it's clear what research question you are doing each operation for!

<!------------------------- Start your work below ----------------------------->

#### Research Question 1: Why are so many of the discounted game prices higher than the non-discounted prices?

There's no extraneous data available on how the discounted prices were calculated. However, determining how much and how often discounts were applied on games over time can help to hypothesize reasons.

To this end, the release years of games were extracted from the `release_date` column of `steam_games`. Next, the dollar amount of how much each game was discounted for was calculated from the `original_price` and `discount_price` columns. To adjust the discounts to amounts comparable to each other, the percentage discounted was taken instead. This was calculated by dividing the discounted dollar amount by the game's original price. As was discovered in the previous mini data analysis, many games had "discounts" of prices several times higher than its original price.

To analyze the distributions of negative discounts over time, all the positive discount values were filtered out, as they are irrelevant. For each year, summary statistics were calculated for the discount percents including maximum, minimum, mean, median, and the 25% and 75% quartiles. Aside from the mean, all of these summary statistics were used to create box plots of the range of negative discounts in each year.

The code for this analysis is shown below:

```{r Research_Q_1}
# Research Question 1: Why are so many of the discounted game prices higher than the non-discounted prices?

# Determine the discount trends over time.

# Make a tibble with the relevant data.
q1_data <- steam_games %>%
  select(name, release_date, original_price, discount_price) %>%
  
  # Remove rows with improperly formatted dates, convert to year.
  filter(!is.na(release_date)) %>%
  filter(grepl(", ", release_date)) %>%
  filter(!grepl("!", release_date)) %>%
  
  # New column for how many dollars each game was discounted for.
  mutate(discount_dollar = original_price - discount_price) %>%
  # New column for what percentage each game was discounted for.
  mutate(discount_percent = as.numeric(discount_dollar / original_price * 100)) %>%
  
  # Remove rows with no discounts
  filter(!is.na(discount_percent)) %>%
  
  # Convert release date strings to date values.
  mutate(release_year = as.numeric(word(release_date, 2, sep = ", "))) %>%
  
  # Remove release date column
  select(-release_date) %>%
  
  # Exercise 1: Compute the range, mean, and two other summary statistics of one numerical variable across the groups of one categorical variable from your data.
 
  # Filter out games with a normal discount of 0-100%
  filter(discount_percent < 0) %>%
  
  # Group by release year
  group_by(release_year) %>%
  
  # Summary of discounts
  summarize("Max" = max(discount_percent), "Min" = min(discount_percent),
            "Median" = median(discount_percent), "Mean" = mean(discount_percent),
            "25% Quartile" = quantile(discount_percent, 0.25),
            "75% Quartile" = quantile(discount_percent, 0.75))

# Exercise 6: Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.
q1_graph <- ggplot(q1_data, aes(x = release_year, y = `Mean`)) +
  
  # Boxplots summarizing the percentage games from each year were discounted
  geom_boxplot(aes(group = release_year, ymin = `Min`, lower = `25% Quartile`,
                   middle = `Median`, upper = `75% Quartile`, ymax = `Max`), 
               stat = "identity", width = 0.75) +
  
  # Format y axis as negative logarithmic
  scale_y_continuous(breaks = c(-10^(5:0), 0), transform = "pseudo_log") +
  guides(y = guide_axis_logticks(negative.small = 1)) +
  
  # Labels
  ggtitle("Negative Discounts of Games Released Over the Years") +
  xlab("Release Year") +
  ylab("% Discounted")

q1_graph
```

The data spanned from 1985 to 2025. As games that didn't have negative discount values were filtered out, only about 11.6 thousand out of 40.8 thousand were counted. The data showed discounts ranging from nearly 0% to less than -10,000%, with more than 75% of applicable games in each year having a negative discount of less than -100%. This would mean the discounted prices were more than twice the original price.

The majority of discounts were above -1,000%, with a few being significantly lower than that. Plotted normally, it would show long tails on the box plots, with the other summary statistics clustered too close to each other to determine any information. To show the range in magnitude of the discounts, I plotted the y-axis as logarithmic.

The plot shows that aside from the late 80's and early 90's, games that had negative discounts tended to have similar ranges of discount percentages. In the past decade, some games were given discount prices closer to 0% of the original, meaning their prices were raised by a small amount. The prices could have been increased due to the games being popular enough to justify pricing it more.

However, a significant minority of games were given discounted prices that were so high, no one would have wanted to buy them. For example, many Call of Duty games were originally priced at \$14.99, but had discounted prices of \$962.60 - a "discount" of -6321%. Cases like these are likely a listing error, especially as the same discounted price was applied to about 20 Call of Duty games. Other similarly discounted games showed the same phenomenon, lending credence to the idea that these high prices were listing errors.

#### Research Question 2: How does the initial price of a game and its computer requirements affect its audience perception?

I decided to plot the hardware requirements and original price of games against their audience perception. The audience perception of a game would be determined from its reviews. Disregarding the number of reviews a game has, only the first section of the `all_reviews` column was extracted. The new `all_reviews` column only included the positive/mixed/negative overall rating.

Hardware requirements of games were extremely varied, and I am not an expert in what makes a good gaming setup. However, by browsing through the `recommended_requirements` column, I found nine categories that most requirement lists had. They were all listed in a single string per row in the `recommended_requirements` column, and were separated by "`:,`" Using this pattern, I made a loop to separate out information labelled as follows: `"Recommended"`, `"OS"`, `"Processor"`, `"Memory"`, `"Graphics"`, `"Storage"`, `"DirectX"`, `"Network",` and `"Sound Card"`.

Instead of plotting each separate requirement category, I instead tallied, for each game, how many categories recommended what I considered the most advanced software listed in the data set. These included a 64-bit processor, Windows 7, an Intel Core i7 processor, 16 GB of memory, a NVIDIA GeForce graphics card, 100 GB of required storage, the Version 11 DirectX system, broadband internet connection, and a DirectX sound card.

Each game was tallied for how many high computer requirements was recommended. Three or fewer of these requirements was considered low, four to six was considered medium, and seven or more was considered high.

To plot all this, a ggplot with two layers was created. A bar graph was generated to show how many games had low to high computer requirements for each review category. On a separate y-axis, a series of box plots were created to show the range of prices these games had. The code for all this is shown below:

```{r Research_Q_2}
# Research Question 2: How does the initial price of a game and its computer requirements affect its audience perception?

# Create tibble of relevant data
q2_data <- steam_games %>%
  select(name, all_reviews, recommended_requirements, original_price) %>%
  
  # Filter games that have data in all fields.
  na.omit() %>%
  
  # Extract audience reviews and filter out ones without a consensus.
  mutate(all_reviews = gsub(",.*$", "", all_reviews)) %>%
  filter(grepl("Positive|Negative|Mixed", all_reviews)) %>%
  mutate(all_reviews = fct_relevel(all_reviews, "Overwhelmingly Positive",
                                   "Very Positive", "Mostly Positive", "Positive",
                                   "Mixed", "Negative", "Mostly Negative",
                                   "Very Negative", "Overwhelmingly Negative"))

# Make new column for each requirement

category_list = list("Recommended", "OS", "Processor", "Memory", "Graphics",
                     "Storage", "DirectX", "Network", "Sound Card")

# For loop to extract text for each requirement in recommended_requirements.
for(category in category_list){
  title_str <- paste("^.*", category, ":,", sep = "")
  
  # Remove everything before category name + ":", inclusive.
  # Then remove everything after the first comma.
  # If there isn't info in for this category, replace with an "NA".
  q2_data <- q2_data %>%
    mutate(col_1 = sub(title_str, "", recommended_requirements),
           col_2 = sub(",.*$", "", col_1),
           !!category := sub("^.*:", NA, col_2))
}
  
# Remove original recommended_requirements column and extraneous columns.
q2_data <- select(q2_data, -recommended_requirements, -col_1, -col_2)

# Exercise 2: Compute the number of observations for at least one of your categorical variables. Do not use the function table()!

# Define high requirements for a game as the most recent version of hardware. 
# Make a list of keywords to search for in each category.
high_reqs <- list("64-bit processor", "Windows 7", "i7", "16 GB", "GeForce", 
                  "100 GB", "Version 11", "Broadband", "DirectX")

q2_data <- mutate(q2_data, "# Requirements" = 0)

# Tally 1 to temp column for each section if it needs the most recent hardware.
for(i in 1:length(category_list)){
  col_name <- toString(category_list[i])
  
  # Add the tally to # Requirements column
  q2_data <- q2_data %>%
    mutate("# Requirements" = `# Requirements` + ifelse(grepl(!!high_reqs[i], 
                                                              !!sym(col_name)), 
                                                        1, 0))
}

q2_data <- q2_data %>%
  # Assign what's considered low to high requirements.
  mutate("Requirements" = ifelse(`# Requirements` <= 3, "Low", 
                                 ifelse(`# Requirements` <= 6, 
                                        "Medium", "High"))) %>%
  mutate("Requirements" = fct_reorder(`Requirements`, `# Requirements`, mean)) %>%
  group_by(`Requirements`)

# Exercise 8: Create a graph that has at least two geom layers.
q2_graph <- ggplot(q2_data, aes(x = all_reviews, fill = Requirements)) +
  # Bar graph of how many games are in each rating with each requirement level
  geom_bar(position = "dodge") +
  
  # Boxplot of the game's original price
  geom_boxplot(aes(x = all_reviews, y = original_price / 0.3)) +
  
  # Separate scale for number of games vs original price
  scale_y_continuous(
    name = "Number of Games", 
    sec.axis = sec_axis(~.*0.3, name = "Original Price ($)")
  ) +
  
  # Labels
  ggtitle("System Requirements of Games", 
          subtitle = "Bar Graph: # of Games with Requirements; Boxplot: Price Range of Games") +
  xlab("User Reviews") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))

q2_graph
```

As shown in the plot, the majority of games had low computer requirements, with only a small minority requiring advanced hardware in all categories. In fact, no games that were rated as overwhelmingly positive, positive, or any kind of negative had high computer requirements. Additionally, most games were priced at under a hundred dollars, with a few games ranging from very positive to mostly negative being priced at up to \$600.

There doesn't seem to be any significant relationship between the computer requirements and original price of a game to how well it is received by an audience. At most, based on the box plots, one can point out that games needing more hardware requirements are more expensive. This makes sense, as games like this would have required more work to make. Additionally, within the 9.5 thousand games that have reviews, a price, and requirements, there are significantly fewer games labeled as negative compared to positive.

#### Research Question 3: Have discounts applied to games affected how they are reviewed recently compared to overall?

To better compare the games' discounts to each other, I plotted the percentage a game was discounted compared to its original price. This was calculated in the same way as for Research Question 1. However, all games with negative discounts were filtered out, as the prices were potentially erroneous, as determined for Research Question 1. Additionally, I extracted both the recent and overall review rating of each game in the same way as for Research Question 2. I then filtered out all games that didn't have information in any of these fields.

For both `recent_reviews` and `all_reviews`, I assigned a score from 1 to 9 to each rating, with 1 being assigned to "Overwhelmingly Positive" and 9 assigned to "Overwhelmingly Negative." I subtracted the recent score from the overall score. If perception on a game recently became worse, then the score would decrease. If it became better, then the score would increase. My theory was that games with higher discounts would have more positive score changes.

I calculated the same summary statistics for game discounts as in Research Question 1, and grouped them by their overall audience review categories. I plotted this a a box plot. However, I discovered that, regardless of discounts, the recent and overall audience reviews were the same for every game. To show this, I plotted a scatter plot of the change in score, which was zero for every category.

The code for all this is shown below:

```{r Research_Q_3}
# Research Question 3: Have discounts applied to games affected how they are reviewed recently compared to overall?

q3_data <- steam_games %>%
  select(name, recent_reviews, all_reviews, original_price, discount_price) %>%
  
  # New column for how many dollars each game was discounted for.
  mutate(discount_dollar = original_price - discount_price) %>%
  # New column for what percentage each game was discounted for.
  mutate(discount_percent = as.numeric(discount_dollar / original_price * 100)) %>%
  # Filter out games that have a negative discount
  filter(discount_percent >= 0) %>%
  
  # Extract audience reviews and filter out ones without a consensus.
  mutate(recent_reviews = gsub(",.*$", "", recent_reviews)) %>%
  filter(grepl("Positive|Negative|Mixed", recent_reviews)) %>%
  # Extract audience reviews and filter out ones without a consensus.
  mutate(all_reviews = gsub(",.*$", "", recent_reviews)) %>%
  filter(grepl("Positive|Negative|Mixed", recent_reviews)) %>%
  
  # Filter games that have data in all fields.
  na.omit() %>%
  select(-original_price, -discount_price, -discount_dollar) %>%
  
  # Exercise 4: Compute the range, mean, and two other summary statistics of one numerical variable across the groups of one categorical variable from your data.
  
  # Convert ratings to numerical representations
  mutate(recent_rating = recode(recent_reviews, "Overwhelmingly Positive" = 1,
                                 "Very Positive" = 2, "Mostly Positive" = 3,
                                 "Positive" = 4, "Mixed" = 5, "Negative" = 6,
                                 "Mostly Negative" = 7, "Very Negative" = 8,
                                 "Overwhelmingly Negative" = 9)) %>%
  mutate(all_rating = recode(all_reviews, "Overwhelmingly Positive" = 1,
                              "Very Positive" = 2, "Mostly Positive" = 3,
                              "Positive" = 4, "Mixed" = 5, "Negative" = 6,
                              "Mostly Negative" = 7, "Very Negative" = 8,
                              "Overwhelmingly Negative" = 9)) %>%
  
  # Determine change in audience perception
  mutate(rating_change = recent_rating - all_rating) %>%
  
  # Summary of discounts
  group_by(all_reviews) %>%
  summarize("Max" = max(discount_percent), "Min" = min(discount_percent),
            "Median" = median(discount_percent), "Mean" = mean(discount_percent),
            "25% Quartile" = quantile(discount_percent, 0.25),
            "75% Quartile" = quantile(discount_percent, 0.75), 
            "Mean Rating Change" = mean(rating_change))

# Exercise 8: Create a graph that has at least two geom layers.
q3_graph <- ggplot(q3_data, aes(x = all_reviews, y = Mean)) +
  # Boxplots summarizing the percentage discounted for each review rating
  geom_boxplot(aes(group = all_reviews, ymin = `Min`, lower = `25% Quartile`,
                   middle = `Median`, upper = `75% Quartile`, ymax = `Max`), 
               stat = "identity", width = 0.75) +
  geom_point(aes(x = all_reviews, y = `Mean Rating Change`)) +
  
  # Separate scale for discounted price and change in rating
  scale_y_continuous(
    name = "% Discounted", 
    sec.axis = sec_axis(~./12, name = "Change in Recent Compared to Overall Rating")
  ) +
  
  # Labels
  ggtitle("Games Discounts Compared to Overall Reviews",
          subtitle = "Boxplot: Range of Discounts; Scatterplot: Average Change in Reviews.") +
  xlab("Overall Reviews")

q3_graph
```

The box plot layer of the plot summarizes similar information to the histograms created in the first data analysis project. Games that are rated as overwhelmingly positive have lower discounts on average than more negatively rated games. Other than that, the most surprising discovery was that discounts had no effect on the overall audience perception of a game.

#### Research Question 4: What genre of games are the most popular to release and play over time?

To answer this question, only the `release_date` and `genre` columns from `steam_data` are needed. This data set has games released over a more than 40-year period, from the 1980s to 2025. Because of the wide range of time, and also because some of the dates are not consistently formatted, the data will only be plotted by year.

The year value was extracted from `release_date`, with oddly formatted dates being filtered out for simplicity. The `genre` column listed every genre that the game was tagged with in one long string. Using `", "` as a delimiter, I created separate columns for each individual genre a game had. The maximum number of genres that a game had was 13.

Next, I summarized the number of games released in each year that had each discrete genre. I plotted this as a line plot, with a separate line for each genre, over time. Significantly more games were released in recent years than in the 80's or 90's, by several orders of magnitude. To make the plot easier to read, I plotted the number of games in each genre on a logarithmic y-axis.

The code for the data analysis is shown below:

```{r Research_Q_4}
# Research Question 4: What genre of games are the most popular to release and play over time?

q4_data <- steam_games %>%
  select(name, release_date, genre) %>%
  
  # Remove rows with improperly formatted dates, convert to year.
  filter(!is.na(release_date)) %>%
  filter(grepl(", ", release_date)) %>%
  filter(!grepl("!", release_date)) %>%
  
  # Convert release date strings to date values.
  mutate(release_year = suppressWarnings(as.numeric(word(release_date, 2, 
                                                         sep = ", ")))) %>%
  select(-release_date) %>%
  drop_na() %>%
  
  # Separate genre column into individual items.
  separate_wider_delim(genre, delim = ",", names_sep = "_", 
                       too_few = "align_start") %>%
  
  # Exercise 2: Compute the number of observations for at least one of your categorical variables. Do not use the function table()!
  
  # Make multiple rows for each game with one genre column
  pivot_longer(cols = starts_with("genre"), names_to = "temp", values_to = "genre",
               values_drop_na = TRUE) %>%
  select(-temp) %>%
  
  # Sort by genre
  group_by(release_year, genre) %>%
  rename("Genre" = genre) %>%
  summarise(n = n(), .groups = "drop_last")

# Exercise 7: Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.
q4_graph <- ggplot(q4_data, aes(x = release_year, y = n, color = Genre)) +
  geom_line() +
  scale_y_continuous(trans = "log10") +
  
  # Labels
  ggtitle("Genres of Games Over Time") +
  xlab("Release Year") +
  ylab("# of Games")

q4_graph
```

Some genres were common since the 80's and continue to be common now, like casual, action, and adventure. Other genres became more common later, like indie or web publishing. Some genres briefly occurred in the 2010's, like accounting, or HTC, though not a lot of games included them. There are 26 distinct genres listed in the data set, which makes this plot very messy to read. To determine overall trends, the plot should only take the most common few genres and plot those.

The number of occurrences of each genre increased significantly by the 2010's, mainly because more games from the 2010's were published on Steam compared to the 80's and 90's. The occurrences of genres decreased in the 2020's because this data set seems to be a few years old, so fewer recent games were listed in the data set.

<!----------------------------------------------------------------------------->

### 1.3 (2 points)

Based on the operations that you've completed, how much closer are you to answering your research questions? Think about what aspects of your research questions remain unclear. Can your research questions be refined, now that you've investigated your data a bit more? Which research questions are yielding interesting results?

<!------------------------- Write your answer here ---------------------------->

#### Research Question 1: Why are so many of the discounted game prices higher than the non-discounted prices?

Although I've been able to visualize how many games had higher discounted prices than the original price, and its trends over time and in relation to audience perception, the research question asks *why* this is. This is more difficult to determine, as there is no data available to determine if contemporary issues in the industry were a factor, or if these prices were listed as a mistake.

It was very surprising to see that so many games had "discounted" prices listed in the hundreds, and the idea that these prices were mistaken is my best theory. It's also unknown when the discounted prices were listed. If there were events happening during the time these games were discounted that would explain why the prices were so high, I wouldn't have the information to determine it. The only way I could research this question further is if I had access to explanations from the people who determined the discounts.

#### Research Question 2: How does the initial price of a game and its computer requirements affect its audience perception?

I was surprised to see no apparent relationship between a game's audience perception and its price and hardware requirements. The idea was that less expensive games that required less sophisticated computer hardware would be more easily accessible by players. This would make them more charitable to the games and give them better reviews. Another anticipated possibility was that, as advanced computer hardware cost a lot of money, the sunk cost in that, as well as a high game price would lead players to be more favorable towards expensive, demanding games, due to the sunk cost fallacy.

There's a possibility that, by simply counting the number of computer requirement categories that listed more advanced tech, I was "averaging out" the data too much. Certain aspects of a gaming setup are likely more important for players than others. What's unclear is whether specific computer requirements might affect the audience's perception of a game. Additionally, the plot I generated indicates that games with higher requirements were more expensive, so I'd also like to determine what specific requirements would make it expensive.

#### Research Question 3: Have discounts applied to games affected how they are reviewed recently compared to overall?

This question can be answered with a solid "no." The plot indicated that regardless of the discounts given to games, recent reviews and overall reviews all reached the same consensus. The only significant pattern shown in the plot for Research Question 3 was also seen in the plots for the first project, where games viewed as overwhelmingly positive were not discounted as much as less beloved games. I am surprised at this conclusion, as I expected discounts to make players more favorable towards a game.

Even if my hypothesis was right, one limitation of this analysis is that I don't know when the discount was listed. The `recent_reviews` column summarized reviews from within one month of when the data set was created, but it's unclear if the discounted price was set significantly before this period or during it. If the discount had been in place for a long time, then even if audiences were more favorable towards a cheaper game, it would have reflected in the overall reviews, and not the recent ones. To determine if this is the case, I would need data detailing when the game was discounted.

#### Research Question 4: What genre of games are the most popular to release and play over time?

To answer this question, I was able to determine 26 distinct genres of games. The line plot I made was a good visualization of the general trends of the popularity of genres over time. Several of the genres that I am familiar with are fairly popular, which I expected. There were also some genres that I had never heard of, which also don't seem too popular. However, because of how many genres there were, the plot was borderline unreadable beyond its shape. To further research this questions, I will narrow down to a number of common genres and plot that.

Also, I haven't examined what genres are popular to play yet. I assume the distribution over the years will be similar to what genres are made, as game developers likely make games with the intention that people will like playing it. I can sort the data based on what genre and what review it got, and see if certain games are more popular than others over time.

<!----------------------------------------------------------------------------->

# Task 2: Tidy your data

In this task, we will do several exercises to reshape our data. The goal here is to understand how to do this reshaping with the `tidyr` package.

A reminder of the definition of *tidy* data:

-   Each row is an **observation**
-   Each column is a **variable**
-   Each cell is a **value**

### 2.1 (2 points)

Based on the definition above, can you identify if your data is tidy or untidy? Go through all your columns, or if you have \>8 variables, just pick 8, and explain whether the data is untidy or tidy.

<!--------------------------- Start your work below --------------------------->

```{r selected_dataset}
selected_data <- steam_games %>%
  select(name, recent_reviews, all_reviews, release_date, 
         developer, genre, original_price, discount_price)

selected_data
```

The columns `recent_reviews`, `all_reviews`, and `genre` are not tidy because they all have more than one value in each cell. `recent_reviews` and `all_reviews` have information on the overall rating of a game, the number of reviews it has, and the percentage of people who reviewed the game a certain way. The `genre` column contains a list of all the genres the game is tagged with.

<!----------------------------------------------------------------------------->

### 2.2 (4 points)

Now, if your data is tidy, untidy it! Then, tidy it back to it's original state.

If your data is untidy, then tidy it! Then, untidy it back to it's original state.

Be sure to explain your reasoning for this task. Show us the "before" and "after".

<!--------------------------- Start your work below --------------------------->

Since my data is untidy, I will tidy it by separating columns with strings of multiple values into multiple columns with individual values. First, I split the `genre` column into individual genres. Next, I split the `recent_reviews` and `all_reviews` columns into columns detailing the rating, number of reviews, and the percentage of positive reviews. Finally, I split the `release_date` column into its month, date, and year components. I also abbreviated the month so it's uniformly 3 letters in every row.

The code tidying the data is shown below:

```{r tidying_data}

tidy_data <- selected_data %>%
  # Split genre column into one column for each genre. 
  separate_wider_delim(genre, delim = ",", names_sep = "_", 
                       too_few = "align_start") %>%
  
  # Split recent reviews into rating & # of reviews, remove extra info
  separate_wider_delim(recent_reviews, delim = ",", 
                       names = c("recent_rating", "recent_reviews"),
                       too_many = "merge", too_few = "align_start") %>%
  separate_wider_delim(recent_reviews, delim = "(", 
                       names = c("x", "recent_reviews"), 
                       too_many = "merge", too_few = "align_start") %>%
  separate_wider_delim(recent_reviews, delim = "),- ", 
                       names = c("recent_reviews", "y"),
                       too_many = "merge", too_few = "align_start") %>%
  separate_wider_delim(y, delim = "%", names = c("recent_percent", "z"),
                       too_many = "merge", too_few = "align_start") %>%
  select(-x, -z) %>%
  mutate(recent_reviews = as.numeric(gsub(",", "", recent_reviews))) %>%
  # Remove NaN values in rating
  mutate(recent_rating = if_else(grepl("NaN", recent_rating), 
                                 NA, recent_rating)) %>%
  # Same for all reviews
  separate_wider_delim(all_reviews, delim = ",", names = c("all_rating",
                                                           "all_reviews"),
                       too_many = "merge", too_few = "align_start") %>%
  separate_wider_delim(all_reviews, delim = "(", 
                       names = c("x", "all_reviews"), 
                       too_many = "merge", too_few = "align_start") %>%
  separate_wider_delim(all_reviews, delim = "),- ", 
                       names = c("all_reviews", "y"),
                       too_many = "merge", too_few = "align_start") %>%
  separate_wider_delim(y, delim = "%", names = c("all_percent", "z"),
                       too_many = "merge", too_few = "align_start") %>%
  select(-x, -z) %>%
  mutate(all_reviews = suppressWarnings(as.numeric(gsub(",", "", all_reviews)))) %>%
  # Format ratings where not enough people reviewed for a consensus.
  mutate(all_rating = if_else(grepl("NaN", all_rating), NA, all_rating)) %>%
  mutate(all_reviews = if_else(grepl("user", all_rating), 
                               suppressWarnings(as.numeric(all_rating[1])), 
                               all_reviews)) %>%
  mutate(all_rating = if_else(grepl("user", all_rating), NA, all_rating)) %>%

  # Format dates. Weirdly formatted dates may be deleted completely.
  separate_wider_delim(release_date, delim = " ", names = c("m", "d", "y"),
                       too_many = "merge", too_few = "align_end") %>%
  # Determine if years were split into other columns.
  mutate(y = if_else(grepl("^[0-9]+$", m), if_else(nchar(m) == 4, m, y), y)) %>%
  mutate(y = if_else(grepl("^[0-9]+$", d), if_else(nchar(d) == 4, d, y), y)) %>%
  # Determine if days were split into other columns.
  mutate(d = gsub(",", "", d)) %>%
  mutate(d = if_else(grepl("^[0-9]+$", y), if_else(nchar(y) != 4, y, d), d)) %>%
  mutate(d = if_else(grepl("^[0-9]+$", m), if_else(nchar(m) != 4, m, d), d)) %>%
  # Determine if months were split into other columns.
  mutate(m = if_else(grepl("Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept|Oct|Nov|Dec", d), 
                     d, m)) %>%
  mutate(m = if_else(grepl("Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept|Oct|Nov|Dec", y), 
                     y, m)) %>%
  # Format year, month, date.
  mutate(y = if_else(grepl("^[0-9]+$", y), if_else(nchar(y) == 4, y, NA), NA)) %>%
  mutate(m = if_else(grepl("Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept|Oct|Nov|Dec", m), 
                     if_else(grepl(" ", m), NA, m), NA)[3]) %>%
  mutate(d = if_else(grepl("^[0-9]+$", d), if_else(nchar(d) <= 2, d, NA), NA))

tidy_data
```

To untidy the data, I combined the `m`, `d`, and `y` columns back into `Release Date`, now formatted more uniformly. I also combined the stats for `recent_reviews` and `all_reviews` back into a singular string in their respective columns. Finally, I combined all the genre columns back into one.

The code untidying the data is shown below:

```{r untidying_data}
untidy_data <- tidy_data %>%
  # Convert m, d, and y columns into one date
  unite("Release Date", m:y, sep = "-", na.rm = TRUE) %>%
  
  # Combine recent review info
  unite(recent_reviews, c(recent_reviews, recent_rating), 
        sep = " Reviews; Average Rating: ", na.rm = TRUE) %>%
  unite("Recent Reviews", c(recent_reviews, recent_percent),
        sep = "; % Positive:", na.rm = TRUE) %>%
  
  # Combine all review info
  unite(all_reviews, c(all_reviews, all_rating),
        sep = " Reviews, Average Rating: ", na.rm = TRUE) %>%
  unite("All Reviews", c(all_reviews, all_percent),
        sep = "; % Positive:", na.rm = TRUE) %>%
  
  # Combine genre back into 1 column
  unite("Genres", genre_1:genre_14, sep = ", ", na.rm = TRUE)

untidy_data
```

<!----------------------------------------------------------------------------->

### 2.3 (4 points)

Now, you should be more familiar with your data, and also have made progress in answering your research questions. Based on your interest, and your analyses, pick 2 of the 4 research questions to continue your analysis in the remaining tasks:

<!-------------------------- Start your work below ---------------------------->

1.  How does the initial price of a game and its computer requirements affect its audience perception?
2.  What genre of games are the most popular to release and play over time?

<!----------------------------------------------------------------------------->

Explain your decision for choosing the above two research questions.

<!--------------------------- Start your work below --------------------------->

I chose the first question because I still wanted to look into if specific computer requirements would affect audience perception. I have concluded that the initial price of a game has no clear connection to audience perception, so I will only look at specific computer requirements.

I chose the second question because I haven't looked into what genres of games are popular to play, only what genres are popular to release. Moreover, I want to narrow it down to a few common genres, and disregard the less common ones that are only applicable to a few games.

<!----------------------------------------------------------------------------->

Now, try to choose a version of your data that you think will be appropriate to answer these 2 questions. Use between 4 and 8 functions that we've covered so far (i.e. by filtering, cleaning, tidying, dropping irrelevant columns, etc.).

(If it makes more sense, then you can make/pick two versions of your data, one for each research question.)

<!--------------------------- Start your work below --------------------------->

The data set I made for New Research Question 1 summarizes how many games in each review rating category requires the most sophisticated hardware in each computer requirement category. The occurrences of games can be plotted to determine if certain computer requirements affect reviews over others.

```{r New_Research_Q_1}
nq1_data <- q2_data %>%
  # Select only the reviews and requirement categories of data.
  ungroup() %>%
  select(-original_price, -`# Requirements`, -Requirements)

# List of categories and qualifiers to cycle through in for loop
category_list = list("Recommended", "OS", "Processor", "Memory", "Graphics",
                     "Storage", "DirectX", "Network", "Sound Card")
high_reqs <- list("64-bit processor", "Windows 7", "i7", "16 GB", "GeForce", 
                  "100 GB", "Version 11", "Broadband", "DirectX")
new_col_name <- list("64-Bit Processor", "Windows 7", "Intel i7 Processor", 
                     "16 GB Memory", "NVIDIA GeForce Graphics", "File Over 100 GB",
                     "DirectX Version 11", "Internet Connection",
                     "DirectX Sound Card")

# Make new columns just checking for the highest requirements
for(i in 1:length(category_list)){
  col_name <- toString(category_list[i])
  
  # Check for requirement and create new column of if it meets requirement.
  nq1_data <- nq1_data %>%
    mutate(!!new_col_name[[i]] := if_else(grepl(!!high_reqs[i], get(col_name)),
                                          TRUE, FALSE))
}

nq1_data <- nq1_data %>%
  # Remove original requirement columns and group by review rating
  select(-Recommended, -OS, -Processor, -Memory, -Graphics, 
         -Storage, -DirectX, -Network, -`Sound Card`) %>%
  
  # Make each requirement into its own row
  pivot_longer(cols = `64-Bit Processor`:`DirectX Sound Card`, 
               names_to = "Requirement", values_to = "Y/N") %>%
  # Only include rows that list something that's required
  filter(`Y/N` == TRUE) %>%
  select(-`Y/N`) %>%
  
  # Summarize requirements
  group_by(all_reviews, Requirement) %>%
  summarise("Occurrences" = n())

nq1_data
```

The data set I made groups games by their year of release, audience rating, and what genre they have. I summarized the occurrence of games in each category, as well as the number of positive reviews that the average game in that category received. This can be plotted to determine what genres are the most popular with audiences in each year.

```{r New_Research_Q_2}
nq2_data <- tidy_data %>%
  # Remove uneccesary columns
  select(-recent_rating, -recent_reviews, -recent_percent, 
         -m, -d, -developer, -original_price, -discount_price) %>%
  
  # Remove columns that don't have years, review percentages, or any genres
  filter(!is.na(y)) %>%
  filter(!is.na(all_percent)) %>%
  filter(!is.na(genre_1)) %>%
  
  # Determine how many positive reviews each game had
  mutate(pos_reviews = as.numeric(all_percent) * as.numeric(all_reviews) / 100) %>%
  select(-all_percent, -all_reviews) %>%
  
  # Make one row for each occurrence of a genre
  pivot_longer(cols = starts_with("genre"), names_to = "temp", values_to = "genre",
               values_drop_na = TRUE) %>%
  select(-temp) %>%
  
  # Summarize how much each genre occurs in each year
  group_by(y, genre, all_rating) %>%
  summarise("Occurrences" = n(), 
            "Positive Reviews" = mean(pos_reviews))
  
nq2_data
```

<!----------------------------------------------------------------------------->

# Task 3: Modelling

## 3.0 (no points)

Pick a research question from 1.2, and pick a variable of interest (we'll call it "Y") that's relevant to the research question. Indicate these.

<!-------------------------- Start your work below ---------------------------->

**Research Question**: How does the initial price of a game and its computer requirements affect its audience perception?

**Variable of interest**: Median initial price of a game

<!----------------------------------------------------------------------------->

## 3.1 (3 points)

Fit a model or run a hypothesis test that provides insight on this variable with respect to the research question. Store the model object as a variable, and print its output to screen. We'll omit having to justify your choice, because we don't expect you to know about model specifics in STAT 545.

-   **Note**: It's OK if you don't know how these models/tests work. Here are some examples of things you can do here, but the sky's the limit.

    -   You could fit a model that makes predictions on Y using another variable, by using the `lm()` function.
    -   You could test whether the mean of Y equals 0 using `t.test()`, or maybe the mean across two groups are different using `t.test()`, or maybe the mean across multiple groups are different using `anova()` (you may have to pivot your data for the latter two).
    -   You could use `lm()` to test for significance of regression coefficients.

<!-------------------------- Start your work below ---------------------------->

This model will determine the relationship between the initial price of a game compared to how many high computer requirements it has. The number of high computer requirements is on a scale from 1-9. There were some games that had absurdly high prices, up to \$600. To determine the average initial price of a game, I grouped the data by games' number of high computer requirements and took the median price of each group.

```{r linear_model}
# x is # of requirements, y is initial game price
linear_model <- q2_data %>%
  # Remove uneccesary columns
  ungroup() %>%
  select(original_price, `# Requirements`) %>%
  
  # Get medians of game prices
  group_by(`# Requirements`) %>%
  summarise(average_price = median(original_price)) %>%
  
  # Linear model
  lm(average_price~`# Requirements`, data = .) %>%
  summary()

linear_model
```

<!----------------------------------------------------------------------------->

## 3.2 (3 points)

Produce something relevant from your fitted model: either predictions on Y, or a single value like a regression coefficient or a p-value.

-   Be sure to indicate in writing what you chose to produce.
-   Your code should either output a tibble (in which case you should indicate the column that contains the thing you're looking for), or the thing you're looking for itself.
-   Obtain your results using the `broom` package if possible. If your model is not compatible with the broom function you're needing, then you can obtain your results by some other means, but first indicate which broom function is not compatible.

<!-------------------------- Start your work below ---------------------------->

I used the glance function to produce a tibble row of various statistics regarding the fit for the linear model between the median initial price of games and the number of high computer requirements they require. The statistics include: the regular and adjusted $R^{2}$, the standard error, the test statistic, its p-value, the normal and residual degrees of freedom, and the number of observations used.

```{r broom_model}
# Make a tibble of linear model fit statistics.
broom_model <- glance(linear_model)

broom_model
```

<!----------------------------------------------------------------------------->

# Task 4: Reading and writing data

Get set up for this exercise by making a folder called `output` in the top level of your project folder / repository. You'll be saving things there.

## 4.1 (3 points)

Take a summary table that you made from Task 1, and write it as a csv file in your `output` folder. Use the `here::here()` function.

-   **Robustness criteria**: You should be able to move your Mini Project repository / project folder to some other location on your computer, or move this very Rmd file to another location within your project repository / folder, and your code should still work.
-   **Reproducibility criteria**: You should be able to delete the csv file, and remake it simply by knitting this Rmd file.

<!-------------------------- Start your work below ---------------------------->

```{r write_to_csv}
write.csv(q4_data,file=here::here("output","q4_data.csv"), row.names=FALSE)
here::here("q4_data.csv")
```

<!----------------------------------------------------------------------------->

## 4.2 (3 points)

Write your model object from Task 3 to an R binary file (an RDS), and load it again. Be sure to save the binary file in your `output` folder. Use the functions `saveRDS()` and `readRDS()`.

-   The same robustness and reproducibility criteria as in 4.1 apply here.

<!-------------------------- Start your work below ---------------------------->

```{r write_to_RDS}
saveRDS(broom_model, "output/Broom_Model.rds")
readRDS("output/Broom_Model.rds")
```

<!----------------------------------------------------------------------------->

# Overall Reproducibility/Cleanliness/Coherence Checklist

Here are the criteria we're looking for.

## Coherence (0.5 points)

The document should read sensibly from top to bottom, with no major continuity errors.

The README file should still satisfy the criteria from the last milestone, i.e. it has been updated to match the changes to the repository made in this milestone.

## File and folder structure (1 points)

You should have at least three folders in the top level of your repository: one for each milestone, and one output folder. If there are any other folders, these are explained in the main README.

Each milestone document is contained in its respective folder, and nowhere else.

Every level-1 folder (that is, the ones stored in the top level, like "Milestone1" and "output") has a `README` file, explaining in a sentence or two what is in the folder, in plain language (it's enough to say something like "This folder contains the source for Milestone 1").

## Output (1 point)

All output is recent and relevant:

-   All Rmd files have been `knit`ted to their output md files.
-   All knitted md files are viewable without errors on Github. Examples of errors: Missing plots, "Sorry about that, but we can't show files that are this big right now" messages, error messages from broken R code
-   All of these output files are up-to-date -- that is, they haven't fallen behind after the source (Rmd) files have been updated.
-   There should be no relic output files. For example, if you were knitting an Rmd to html, but then changed the output to be only a markdown file, then the html file is a relic and should be deleted.

Our recommendation: delete all output files, and re-knit each milestone's Rmd file, so that everything is up to date and relevant.

## Tagged release (0.5 point)

You've tagged a release for Milestone 2.
